{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/2017soft/MovieReview/blob/master/transformer_distill_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POyKpaJ265-k",
    "outputId": "b031aa4a-e3d1-429f-9019-307e0316e8b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2Emc8MOH7Aeg"
   },
   "outputs": [],
   "source": [
    "!cp 'drive/My Drive/utils.py' ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BcNra2cn65-q"
   },
   "outputs": [],
   "source": [
    "from utils import read_data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GB9gfLFf8Bee",
    "outputId": "4e46536c-a43c-4949-fec1-fcec836bfce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              REVIEW  SENTIMENT\n",
      "0  A series of escapades demonstrating the adage ...          1\n",
      "1  A series of escapades demonstrating the adage ...          2\n",
      "2                                           A series          2\n",
      "3                                                  A          2\n",
      "4                                             series          2\n"
     ]
    }
   ],
   "source": [
    "df = read_data_csv('dataset.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nACmpWt--M4J",
    "outputId": "84fdf254-8424-4558-cd97-d7d2f27ab0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7GAavGrKpf3",
    "outputId": "86c6ba26-7273-47ad-8e47-80eab857b630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ocSIOruCLUw7"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 64\n",
    "TRAIN_BATCH_SIZE = 500\n",
    "VALID_BATCH_SIZE = 500\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MrPooBNkLwGi"
   },
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        review = str(self.data.REVIEW[index])\n",
    "        review = \" \".join(review.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.SENTIMENT[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4MobM8Z4w5A",
    "outputId": "e8ea912f-b878-45fa-d458-54229e152f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (156060, 2)\n",
      "TRAIN Dataset: (148257, 2)\n",
      "TEST Dataset: (7803, 2)\n"
     ]
    }
   ],
   "source": [
    "random_seed = 0\n",
    "train_size = 0.95\n",
    "train_dataset=df.sample(frac=train_size,random_state=random_seed)\n",
    "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C-tLqBEFSOX_"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFKQ36PxOmSH"
   },
   "source": [
    "# Define the modified DistillBERT model for this sentiment classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hzJETzTOSSYp"
   },
   "outputs": [],
   "source": [
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yb-CaNSsSV63",
    "outputId": "edc5dc8c-e6f9-4c82-fdf9-d1401e9a2477"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistillBERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4d7EB6jO9Qv"
   },
   "source": [
    "# Create the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "u194A6wgSYgk"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5r0FjuoAPUYz"
   },
   "source": [
    "# Import the training and validation function for tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gmVhq5sSTFHd"
   },
   "outputs": [],
   "source": [
    "from utils import train, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training and validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vzQhRtjGO7R2"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vV4P3YtnUJjM",
    "outputId": "7a4afa54-d8b3-404c-ba3b-23d54c0ff01b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 297 batches in the training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss after step 0: 1.616094708442688\n",
      "Training Accuracy after step 0: 11.8\n",
      "Training Loss after step 50: 1.3399755370383168\n",
      "Training Accuracy after step 50: 47.227450980392156\n",
      "Training Loss after step 100: 1.2791901177699023\n",
      "Training Accuracy after step 100: 49.073267326732676\n",
      "Training Loss after step 150: 1.2547213873326384\n",
      "Training Accuracy after step 150: 49.87152317880795\n",
      "Training Loss after step 200: 1.2415462726384252\n",
      "Training Accuracy after step 200: 50.24676616915423\n",
      "Training Loss after step 250: 1.2293505103464621\n",
      "Training Accuracy after step 250: 50.70677290836653\n",
      "The Total Accuracy for Epoch 0: 50.92643180423184\n",
      "Training Loss Epoch 0: 1.220914981983326\n",
      "Training Accuracy Epoch 0: 50.92643180423184\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 1.165771722793579\n",
      "Validation Accuracy after 0 steps: 51.6\n",
      "Validation Loss after 10 steps: 1.1380802176215432\n",
      "Validation Accuracy after 10 steps: 53.472727272727276\n",
      "Validation Loss after Epoch 0: 1.1358964517712593\n",
      "Validation Accuracy after Epoch 0: 54.06894784057414\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 1.184407353401184\n",
      "Training Accuracy after step 0: 51.2\n",
      "Training Loss after step 50: 1.1524264438479555\n",
      "Training Accuracy after step 50: 53.1921568627451\n",
      "Training Loss after step 100: 1.1436414057665532\n",
      "Training Accuracy after step 100: 53.744554455445545\n",
      "Training Loss after step 150: 1.1377685425297315\n",
      "Training Accuracy after step 150: 53.92185430463576\n",
      "Training Loss after step 200: 1.1275050954439154\n",
      "Training Accuracy after step 200: 54.450746268656715\n",
      "Training Loss after step 250: 1.1193393459358063\n",
      "Training Accuracy after step 250: 54.797609561752985\n",
      "The Total Accuracy for Epoch 1: 55.10633561990328\n",
      "Training Loss Epoch 1: 1.111639390489469\n",
      "Training Accuracy Epoch 1: 55.10633561990328\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 1.0620677471160889\n",
      "Validation Accuracy after 0 steps: 59.8\n",
      "Validation Loss after 10 steps: 1.0293749408288435\n",
      "Validation Accuracy after 10 steps: 58.27272727272727\n",
      "Validation Loss after Epoch 1: 1.0324683375656605\n",
      "Validation Accuracy after Epoch 1: 58.41343073176983\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 1.0133512020111084\n",
      "Training Accuracy after step 0: 60.4\n",
      "Training Loss after step 50: 1.026240907463373\n",
      "Training Accuracy after step 50: 58.66274509803922\n",
      "Training Loss after step 100: 1.0216477584130694\n",
      "Training Accuracy after step 100: 58.934653465346535\n",
      "Training Loss after step 150: 1.0141294878839657\n",
      "Training Accuracy after step 150: 59.263576158940396\n",
      "Training Loss after step 200: 1.0089336651474683\n",
      "Training Accuracy after step 200: 59.407960199004975\n",
      "Training Loss after step 250: 1.0029600414621878\n",
      "Training Accuracy after step 250: 59.679681274900396\n",
      "The Total Accuracy for Epoch 2: 59.93106564951402\n",
      "Training Loss Epoch 2: 0.99670513390692\n",
      "Training Accuracy Epoch 2: 59.93106564951402\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.9473559856414795\n",
      "Validation Accuracy after 0 steps: 62.2\n",
      "Validation Loss after 10 steps: 0.9394621036269448\n",
      "Validation Accuracy after 10 steps: 62.81818181818182\n",
      "Validation Loss after Epoch 2: 0.9299200475215912\n",
      "Validation Accuracy after Epoch 2: 63.11674996796104\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 0.9555513262748718\n",
      "Training Accuracy after step 0: 62.2\n",
      "Training Loss after step 50: 0.9298755748599183\n",
      "Training Accuracy after step 50: 62.529411764705884\n",
      "Training Loss after step 100: 0.9282322313525889\n",
      "Training Accuracy after step 100: 62.635643564356435\n",
      "Training Loss after step 150: 0.9275376330937771\n",
      "Training Accuracy after step 150: 62.6317880794702\n",
      "Training Loss after step 200: 0.9216668668077953\n",
      "Training Accuracy after step 200: 62.91243781094527\n",
      "Training Loss after step 250: 0.9164740122646925\n",
      "Training Accuracy after step 250: 63.17131474103586\n",
      "The Total Accuracy for Epoch 3: 63.30898372420864\n",
      "Training Loss Epoch 3: 0.9121242689363884\n",
      "Training Accuracy Epoch 3: 63.30898372420864\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.9468866586685181\n",
      "Validation Accuracy after 0 steps: 63.0\n",
      "Validation Loss after 10 steps: 0.890681732784618\n",
      "Validation Accuracy after 10 steps: 64.8\n",
      "Validation Loss after Epoch 3: 0.897861335426569\n",
      "Validation Accuracy after Epoch 3: 64.59054209919262\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 0.8945169448852539\n",
      "Training Accuracy after step 0: 63.0\n",
      "Training Loss after step 50: 0.8654555760177911\n",
      "Training Accuracy after step 50: 65.07450980392157\n",
      "Training Loss after step 100: 0.8632026090480314\n",
      "Training Accuracy after step 100: 65.25544554455446\n",
      "Training Loss after step 150: 0.8608722299929487\n",
      "Training Accuracy after step 150: 65.32980132450331\n",
      "Training Loss after step 200: 0.8595401036798658\n",
      "Training Accuracy after step 200: 65.33134328358209\n",
      "Training Loss after step 250: 0.8581888020276074\n",
      "Training Accuracy after step 250: 65.34661354581674\n",
      "The Total Accuracy for Epoch 4: 65.36150063740666\n",
      "Training Loss Epoch 4: 0.8575744107114747\n",
      "Training Accuracy Epoch 4: 65.36150063740666\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.8539590835571289\n",
      "Validation Accuracy after 0 steps: 67.0\n",
      "Validation Loss after 10 steps: 0.8577647317539562\n",
      "Validation Accuracy after 10 steps: 65.41818181818182\n",
      "Validation Loss after Epoch 4: 0.8604993261396885\n",
      "Validation Accuracy after Epoch 4: 65.359477124183\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 0.791459858417511\n",
      "Training Accuracy after step 0: 69.0\n",
      "Training Loss after step 50: 0.8189262923072366\n",
      "Training Accuracy after step 50: 67.12941176470588\n",
      "Training Loss after step 100: 0.8192355249187734\n",
      "Training Accuracy after step 100: 66.93861386138614\n",
      "Training Loss after step 150: 0.8189616033573024\n",
      "Training Accuracy after step 150: 67.00794701986754\n",
      "Training Loss after step 200: 0.818776610478833\n",
      "Training Accuracy after step 200: 66.9542288557214\n",
      "Training Loss after step 250: 0.8185703224869838\n",
      "Training Accuracy after step 250: 66.89561752988048\n",
      "The Total Accuracy for Epoch 5: 66.86969249344044\n",
      "Training Loss Epoch 5: 0.8182996435197516\n",
      "Training Accuracy Epoch 5: 66.86969249344044\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.8761709332466125\n",
      "Validation Accuracy after 0 steps: 65.6\n",
      "Validation Loss after 10 steps: 0.8467142419381575\n",
      "Validation Accuracy after 10 steps: 66.0909090909091\n",
      "Validation Loss after Epoch 5: 0.848239179700613\n",
      "Validation Accuracy after Epoch 5: 65.70549788542868\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 0.8190076947212219\n",
      "Training Accuracy after step 0: 67.4\n",
      "Training Loss after step 50: 0.7795115907986959\n",
      "Training Accuracy after step 50: 68.27843137254902\n",
      "Training Loss after step 100: 0.7814863648745093\n",
      "Training Accuracy after step 100: 68.24356435643564\n",
      "Training Loss after step 150: 0.7802955875333571\n",
      "Training Accuracy after step 150: 68.27417218543046\n",
      "Training Loss after step 200: 0.7821527675016603\n",
      "Training Accuracy after step 200: 68.2407960199005\n",
      "Training Loss after step 250: 0.7812357267060602\n",
      "Training Accuracy after step 250: 68.26693227091633\n",
      "The Total Accuracy for Epoch 6: 68.21937581362094\n",
      "Training Loss Epoch 6: 0.7818833184161973\n",
      "Training Accuracy Epoch 6: 68.21937581362094\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.8110645413398743\n",
      "Validation Accuracy after 0 steps: 67.6\n",
      "Validation Loss after 10 steps: 0.8325102491812273\n",
      "Validation Accuracy after 10 steps: 65.9090909090909\n",
      "Validation Loss after Epoch 6: 0.8247579224407673\n",
      "Validation Accuracy after Epoch 6: 66.67948225041651\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 0.7269747853279114\n",
      "Training Accuracy after step 0: 71.6\n",
      "Training Loss after step 50: 0.7543376672501657\n",
      "Training Accuracy after step 50: 69.84313725490196\n",
      "Training Loss after step 100: 0.75490141269004\n",
      "Training Accuracy after step 100: 69.61386138613861\n",
      "Training Loss after step 150: 0.7564834995775034\n",
      "Training Accuracy after step 150: 69.51258278145696\n",
      "Training Loss after step 200: 0.7572384571554649\n",
      "Training Accuracy after step 200: 69.47164179104477\n",
      "Training Loss after step 250: 0.7552059378282008\n",
      "Training Accuracy after step 250: 69.42470119521913\n",
      "The Total Accuracy for Epoch 7: 69.40920158913238\n",
      "Training Loss Epoch 7: 0.7560703569791133\n",
      "Training Accuracy Epoch 7: 69.40920158913238\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.8454726934432983\n",
      "Validation Accuracy after 0 steps: 66.8\n",
      "Validation Loss after 10 steps: 0.81528855453838\n",
      "Validation Accuracy after 10 steps: 67.07272727272728\n",
      "Validation Loss after Epoch 7: 0.8276721090078354\n",
      "Validation Accuracy after Epoch 7: 67.1280276816609\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 0.7397585511207581\n",
      "Training Accuracy after step 0: 72.4\n",
      "Training Loss after step 50: 0.7358204371788922\n",
      "Training Accuracy after step 50: 69.92941176470588\n",
      "Training Loss after step 100: 0.7333298396356035\n",
      "Training Accuracy after step 100: 70.14653465346535\n",
      "Training Loss after step 150: 0.7310155649848332\n",
      "Training Accuracy after step 150: 70.16953642384107\n",
      "Training Loss after step 200: 0.7321982170218853\n",
      "Training Accuracy after step 200: 70.20696517412935\n",
      "Training Loss after step 250: 0.7316823789322994\n",
      "Training Accuracy after step 250: 70.2223107569721\n",
      "The Total Accuracy for Epoch 8: 70.24154002846409\n",
      "Training Loss Epoch 8: 0.7311344889277962\n",
      "Training Accuracy Epoch 8: 70.24154002846409\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.8410321474075317\n",
      "Validation Accuracy after 0 steps: 66.6\n",
      "Validation Loss after 10 steps: 0.8272127184000883\n",
      "Validation Accuracy after 10 steps: 67.38181818181818\n",
      "Validation Loss after Epoch 8: 0.8306908681988716\n",
      "Validation Accuracy after Epoch 8: 67.39715494040753\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 0.6702100038528442\n",
      "Training Accuracy after step 0: 72.8\n",
      "Training Loss after step 50: 0.6975008588211209\n",
      "Training Accuracy after step 50: 71.74901960784314\n",
      "Training Loss after step 100: 0.6987281300053738\n",
      "Training Accuracy after step 100: 71.64158415841584\n",
      "Training Loss after step 150: 0.7050923760363598\n",
      "Training Accuracy after step 150: 71.40132450331126\n",
      "Training Loss after step 200: 0.7079694099094144\n",
      "Training Accuracy after step 200: 71.27562189054727\n",
      "Training Loss after step 250: 0.7090107708338247\n",
      "Training Accuracy after step 250: 71.20717131474103\n",
      "The Total Accuracy for Epoch 9: 71.15481899674215\n",
      "Training Loss Epoch 9: 0.7101151786669336\n",
      "Training Accuracy Epoch 9: 71.15481899674215\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.7889444231987\n",
      "Validation Accuracy after 0 steps: 67.6\n",
      "Validation Loss after 10 steps: 0.8154500939629294\n",
      "Validation Accuracy after 10 steps: 67.41818181818182\n",
      "Validation Loss after Epoch 9: 0.8203085027635098\n",
      "Validation Accuracy after Epoch 9: 66.92297834166347\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  train(model, training_loader, loss_function, optimizer, epoch, device)\n",
    "  valid(model, testing_loader, loss_function, epoch, device)\n",
    "  if epoch % 3 == 0:\n",
    "    torch.save(model.state_dict(), f\"drive/My Drive/my_distillbert_model_{datetime.now()}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E23cuP8zAqyM"
   },
   "source": [
    "# Save the model for further training and inference later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ouBXDybn1UyW"
   },
   "outputs": [],
   "source": [
    "model_path = f\"drive/My Drive/my_distillbert_model_{datetime.now()}.pt\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Beb9h2nYvKf1"
   },
   "source": [
    "# Retrieve the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_GyMDnDvT9t",
    "outputId": "5cf2dc40-bebd-4620-8793-daa5df751467"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model = DistillBERTClass()\n",
    "saved_model.load_state_dict(torch.load(model_path))\n",
    "saved_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oFXQ-f4ve3sc"
   },
   "outputs": [],
   "source": [
    "saved_model_loss_function = torch.nn.CrossEntropyLoss()\n",
    "saved_model_optimizer = torch.optim.Adam(params =  saved_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOHzymIRUhIk"
   },
   "source": [
    "# Train the saved model for more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3WGXIkx1sW_",
    "outputId": "0a11b046-4026-434b-fec9-9b2cd092363c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 297 batches in the training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss after step 0: 0.6865410804748535\n",
      "Training Accuracy after step 0: 72.6\n",
      "Training Loss after step 50: 0.7018031279246012\n",
      "Training Accuracy after step 50: 71.70196078431373\n",
      "Training Loss after step 100: 0.6931082883683761\n",
      "Training Accuracy after step 100: 71.97821782178218\n",
      "Training Loss after step 150: 0.6909897820839029\n",
      "Training Accuracy after step 150: 71.9841059602649\n",
      "Training Loss after step 200: 0.6909190923420351\n",
      "Training Accuracy after step 200: 71.9820895522388\n",
      "Training Loss after step 250: 0.6910970702589271\n",
      "Training Accuracy after step 250: 71.9617529880478\n",
      "The Total Accuracy for Epoch 0: 71.9156599688379\n",
      "Training Loss Epoch 0: 0.6913075441061848\n",
      "Training Accuracy Epoch 0: 71.9156599688379\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.7640259861946106\n",
      "Validation Accuracy after 0 steps: 69.8\n",
      "Validation Loss after 10 steps: 0.8115146105939691\n",
      "Validation Accuracy after 10 steps: 67.67272727272727\n",
      "Validation Loss after Epoch 0: 0.8194257318973541\n",
      "Validation Accuracy after Epoch 0: 67.46123285915674\n",
      "There are 297 batches in the training set\n",
      "Training Loss after step 0: 0.6730647087097168\n",
      "Training Accuracy after step 0: 73.2\n",
      "Training Loss after step 50: 0.6674732612628563\n",
      "Training Accuracy after step 50: 72.65490196078431\n",
      "Training Loss after step 100: 0.6708493061585001\n",
      "Training Accuracy after step 100: 72.52079207920792\n",
      "Training Loss after step 150: 0.6711317008694276\n",
      "Training Accuracy after step 150: 72.558940397351\n",
      "Training Loss after step 200: 0.6714764557667633\n",
      "Training Accuracy after step 200: 72.58208955223881\n",
      "Training Loss after step 250: 0.6728329986215112\n",
      "Training Accuracy after step 250: 72.5410358565737\n",
      "The Total Accuracy for Epoch 1: 72.47954565383085\n",
      "Training Loss Epoch 1: 0.673401790235179\n",
      "Training Accuracy Epoch 1: 72.47954565383085\n",
      "There are 16 batches in the test set\n",
      "Validation Loss after 0 steps: 0.7574182152748108\n",
      "Validation Accuracy after 0 steps: 71.8\n",
      "Validation Loss after 10 steps: 0.8081857453693043\n",
      "Validation Accuracy after 10 steps: 68.14545454545454\n",
      "Validation Loss after Epoch 1: 0.8175690285861492\n",
      "Validation Accuracy after Epoch 1: 68.01230296039985\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    train(saved_model, training_loader, saved_model_loss_function, saved_model_optimizer, epoch, device)\n",
    "    valid(saved_model, testing_loader, saved_model_loss_function, epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMNQBIlgTo1_"
   },
   "source": [
    "### Part of the code in this notebook is modified from the tutorial here https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGJ_utkZTpyz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "transformer_distill_bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
